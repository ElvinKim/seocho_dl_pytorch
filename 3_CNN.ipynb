{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3.CNN.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fstyv2SWDyNG",
        "colab_type": "text"
      },
      "source": [
        "# CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hBaTxvd-IcU3",
        "colab_type": "text"
      },
      "source": [
        "## 0. SoftMax"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UBc98-MkiAVS",
        "colab_type": "code",
        "outputId": "7a397afb-8e47-47a9-98a0-da19c2551f8f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "a = np.array([0.3, 2.9, 4.0])\n",
        "\n",
        "exp_a = np.exp(a)\n",
        "\n",
        "print(exp_a)\n",
        "\n",
        "sum_exp_a = np.sum(exp_a)\n",
        "\n",
        "y = exp_a / sum_exp_a\n",
        "\n",
        "print(y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 1.34985881 18.17414537 54.59815003]\n",
            "[0.01821127 0.24519181 0.73659691]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WwpjwyzVD118",
        "colab_type": "text"
      },
      "source": [
        "## 1. MLP VS CNN with CIFAR-10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGjlbeJFWOxd",
        "colab_type": "text"
      },
      "source": [
        "### 1.1 MLP Model with CIFAR-10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zN4EMP9uDvPW",
        "colab_type": "text"
      },
      "source": [
        "중요 모듈 import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-SU2ruZ701H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.datasets as dsets\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchsummary import summary"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_w8qiHwHEFyc",
        "colab_type": "text"
      },
      "source": [
        "Hyper Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fgdhaNqlEHWw",
        "colab_type": "code",
        "outputId": "831a92aa-ed31-4d30-ae14-734b8236e7cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "batch_size = 100\n",
        "total_epoch = 50\n",
        "learning_rate = 0.01\n",
        "use_cuda = torch.cuda.is_available()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "print(use_cuda)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_xzvgvD1ESbQ",
        "colab_type": "text"
      },
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQ0prMG3EQxi",
        "colab_type": "code",
        "outputId": "5f5f0bdd-4357-464a-d31e-b75965c0a991",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "train_dataset = dsets.CIFAR10(root='./data', train=True, transform=transforms.ToTensor(), download=True)\n",
        "test_dataset = dsets.CIFAR10(root='./data', train=False, transform=transforms.ToTensor())\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJtqH-YMIiOK",
        "colab_type": "text"
      },
      "source": [
        "Training Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dUaT2yUEIj73",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model,train_loader):\n",
        "    model.train()\n",
        "    \n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "    losses = []\n",
        "    for i, (image, label) in enumerate(train_loader):\n",
        "        \n",
        "        if use_cuda:\n",
        "            image = image.cuda()\n",
        "            label = label.cuda()\n",
        "        \n",
        "        pred_label = model(image)\n",
        "        loss = criterion(pred_label, label)\n",
        "        losses.append(loss.item())\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    avg_loss = sum(losses)/len(losses)\n",
        "    return avg_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fJgn4fBsKXHF",
        "colab_type": "text"
      },
      "source": [
        "Evaluation Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ouaNCPAUKUzF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def eval(model, test_loader):\n",
        "    model.eval()\n",
        "    device = next(model.parameters()).device.index\n",
        "    \n",
        "    total_cnt = 0\n",
        "    correct_cnt = 0\n",
        "    \n",
        "    for i, (image, label) in enumerate(test_loader):\n",
        "        if use_cuda:\n",
        "            image = image.cuda()\n",
        "            label = label.cuda()\n",
        "\n",
        "        out = model(image)\n",
        "        _, pred_label = torch.max(out.data, 1)\n",
        "        total_cnt += image.data.size()[0]\n",
        "        correct_cnt += (pred_label == label.data).sum().item()\n",
        "        \n",
        "    return correct_cnt / total_cnt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K9NbhDoXEkH_",
        "colab_type": "text"
      },
      "source": [
        "CIFAR10 MLP Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U933Akt8Ed8x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SimpleMLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleMLP, self).__init__()\n",
        "        \n",
        "        # Fully-connected layer\n",
        "        self.fc1 = nn.Linear(3*32*32, 8*28*28)\n",
        "        self.act1 = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(8*28*28, 8*24*24)\n",
        "        self.act2 = nn.ReLU()\n",
        "        self.fc3 = nn.Linear(8*24*24, 16*8*8)\n",
        "        self.act3 = nn.ReLU()\n",
        "        self.fc4 = nn.Linear(16*8*8, 16*4*4)\n",
        "        self.act4 = nn.ReLU()\n",
        "\n",
        "        # Output layer\n",
        "        self.out = nn.Linear(16*4*4, 10)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 3*32*32)\n",
        "        \n",
        "        x = self.act1(self.fc1(x))\n",
        "        x = self.act2(self.fc2(x))\n",
        "        x = self.act3(self.fc3(x))\n",
        "        x = self.act4(self.fc4(x))\n",
        "        \n",
        "        out = self.out(x)\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Xq6rmD7OG1q",
        "colab_type": "text"
      },
      "source": [
        "Training & Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQKiUxZVKZY8",
        "colab_type": "code",
        "outputId": "47629397-6fb2-4295-dbca-645acbe125cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "mlp_model = SimpleMLP().cuda()\n",
        "train_loss_lst = []\n",
        "test_accuracy_lst = []\n",
        "for epoch in range(total_epoch):\n",
        "    train_loss = train(mlp_model, train_loader)\n",
        "    train_loss_lst.append(train_loss)\n",
        "    test_accuracy = eval(mlp_model, test_loader)\n",
        "    test_accuracy_lst.append(test_accuracy)\n",
        "    \n",
        "    print(test_accuracy)\n",
        "\n",
        "summary(mlp_model, input_size = (3,32,32))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.1567\n",
            "0.2081\n",
            "0.2752\n",
            "0.308\n",
            "0.3142\n",
            "0.3395\n",
            "0.3603\n",
            "0.3466\n",
            "0.3948\n",
            "0.4015\n",
            "0.3944\n",
            "0.424\n",
            "0.4405\n",
            "0.4516\n",
            "0.4641\n",
            "0.4568\n",
            "0.4581\n",
            "0.4653\n",
            "0.4758\n",
            "0.4635\n",
            "0.4834\n",
            "0.5033\n",
            "0.5018\n",
            "0.4948\n",
            "0.4902\n",
            "0.4812\n",
            "0.5108\n",
            "0.5233\n",
            "0.4582\n",
            "0.5249\n",
            "0.5332\n",
            "0.5231\n",
            "0.4913\n",
            "0.5185\n",
            "0.5031\n",
            "0.5442\n",
            "0.496\n",
            "0.5373\n",
            "0.5375\n",
            "0.4629\n",
            "0.5337\n",
            "0.5366\n",
            "0.5282\n",
            "0.5319\n",
            "0.5477\n",
            "0.5195\n",
            "0.5525\n",
            "0.5264\n",
            "0.5632\n",
            "0.5219\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Linear-1                 [-1, 6272]      19,273,856\n",
            "              ReLU-2                 [-1, 6272]               0\n",
            "            Linear-3                 [-1, 4608]      28,905,984\n",
            "              ReLU-4                 [-1, 4608]               0\n",
            "            Linear-5                 [-1, 1024]       4,719,616\n",
            "              ReLU-6                 [-1, 1024]               0\n",
            "            Linear-7                  [-1, 256]         262,400\n",
            "              ReLU-8                  [-1, 256]               0\n",
            "            Linear-9                   [-1, 10]           2,570\n",
            "================================================================\n",
            "Total params: 53,164,426\n",
            "Trainable params: 53,164,426\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 0.19\n",
            "Params size (MB): 202.81\n",
            "Estimated Total Size (MB): 203.00\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p9Y0a91SX_HZ",
        "colab_type": "text"
      },
      "source": [
        "### 1.2 CNN Model with CIFAR-10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fx4EC-1vYR03",
        "colab_type": "text"
      },
      "source": [
        "중요 모듈 import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A0D93zO-NW98",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.datasets as dsets\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchsummary import summary"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8i7SC2p1YUjJ",
        "colab_type": "text"
      },
      "source": [
        "Hyper Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g5iG75TMYZKf",
        "colab_type": "code",
        "outputId": "0a6166eb-87a6-42de-b6bb-e27a3d5474b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "batch_size = 100\n",
        "total_epoch = 50\n",
        "learning_rate = 0.001\n",
        "use_cuda = torch.cuda.is_available()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "print(use_cuda)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OkXJo4AfYZ7l",
        "colab_type": "text"
      },
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHaKdbG6YcbV",
        "colab_type": "code",
        "outputId": "05eb31f8-cac2-4e49-c43d-ad3b43196a4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "train_dataset = dsets.CIFAR10(root='./data', train=True, transform=transforms.ToTensor(), download=True)\n",
        "test_dataset = dsets.CIFAR10(root='./data', train=False, transform=transforms.ToTensor())\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OKPHAJKEYhWd",
        "colab_type": "text"
      },
      "source": [
        "CIFAR10 CNN Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4RZONSjJm1O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        # Convolution layer\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=2, padding=1)\n",
        "        self.act1 = nn.ReLU()\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2)\n",
        "        \n",
        "        self.conv2 = nn.Conv2d(64, 192, kernel_size=3, padding=1)\n",
        "        self.act2 = nn.ReLU()\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2)\n",
        "        \n",
        "        self.conv3 = nn.Conv2d(192, 384, kernel_size=3, padding=1)\n",
        "        self.act3 = nn.ReLU()\n",
        "        \n",
        "        self.conv4 = nn.Conv2d(384, 256, kernel_size=3, padding=1)\n",
        "        self.act4 = nn.ReLU()\n",
        "        self.pool3 = nn.MaxPool2d(kernel_size=2)\n",
        "        \n",
        "        # Fully-Connected layer\n",
        "        self.fc1 = nn.Linear(256 * 2* 2, 1000)\n",
        "        self.act5 = nn.ReLU()\n",
        "        self.output = nn.Linear(1000, 10)\n",
        "        \n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.pool1(self.act1(self.conv1(x)))\n",
        "        x = self.pool2(self.act2(self.conv2(x)))\n",
        "        x = self.act3(self.conv3(x))\n",
        "        x = self.act4(self.conv4(x))\n",
        "        x = self.pool3(x)\n",
        "        \n",
        "        x = x.view(-1, 256 * 2 * 2)\n",
        "        \n",
        "        x = self.act5(self.fc1(x))\n",
        "        out = self.output(x)\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BscJ3eLRQB6j",
        "colab_type": "text"
      },
      "source": [
        "Training Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KqEP2Xk4OSAt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model,train_loader):\n",
        "    model.train()\n",
        "    \n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "    losses = []\n",
        "    for i, (image, label) in enumerate(train_loader):\n",
        "        \n",
        "        if use_cuda:\n",
        "            image = image.cuda()\n",
        "            label = label.cuda()\n",
        "        \n",
        "        pred_label = model(image)\n",
        "        loss = criterion(pred_label, label)\n",
        "        losses.append(loss.item())\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    avg_loss = sum(losses)/len(losses)\n",
        "    return avg_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aqg3JnTRQEIs",
        "colab_type": "text"
      },
      "source": [
        "Evaluation Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdbhRae8OUAV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def eval(model, test_loader):\n",
        "    model.eval()\n",
        "    device = next(model.parameters()).device.index\n",
        "    \n",
        "    total_cnt = 0\n",
        "    correct_cnt = 0\n",
        "    \n",
        "    for i, (image, label) in enumerate(test_loader):\n",
        "        if use_cuda:\n",
        "            image = image.cuda()\n",
        "            label = label.cuda()\n",
        "\n",
        "        out = model(image)\n",
        "        _, pred_label = torch.max(out.data, 1)\n",
        "        total_cnt += image.data.size()[0]\n",
        "        correct_cnt += (pred_label == label.data).sum().item()\n",
        "        \n",
        "    return correct_cnt / total_cnt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M7n0U0gZQGyH",
        "colab_type": "text"
      },
      "source": [
        "Training & Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eciwGiTHNJoM",
        "colab_type": "code",
        "outputId": "2b34a1db-0278-4c53-f05b-abcebf1fd8dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "cnn_model = SimpleCNN().cuda()\n",
        "train_loss_lst = []\n",
        "test_accuracy_lst = []\n",
        "for epoch in range(total_epoch):\n",
        "    train_loss = train(cnn_model, train_loader)\n",
        "    train_loss_lst.append(train_loss)\n",
        "    test_accuracy = eval(cnn_model, test_loader)\n",
        "    test_accuracy_lst.append(test_accuracy)\n",
        "    \n",
        "    print(test_accuracy)\n",
        "\n",
        "summary(cnn_model, input_size = (3,32,32))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.1007\n",
            "0.1143\n",
            "0.1852\n",
            "0.2514\n",
            "0.2611\n",
            "0.2856\n",
            "0.2866\n",
            "0.3274\n",
            "0.3762\n",
            "0.3845\n",
            "0.4125\n",
            "0.4276\n",
            "0.4374\n",
            "0.4615\n",
            "0.473\n",
            "0.4891\n",
            "0.4941\n",
            "0.4858\n",
            "0.5053\n",
            "0.5111\n",
            "0.4971\n",
            "0.5579\n",
            "0.5513\n",
            "0.5728\n",
            "0.5844\n",
            "0.5792\n",
            "0.5828\n",
            "0.601\n",
            "0.6087\n",
            "0.6155\n",
            "0.6067\n",
            "0.6223\n",
            "0.6386\n",
            "0.6408\n",
            "0.6396\n",
            "0.651\n",
            "0.6619\n",
            "0.664\n",
            "0.6717\n",
            "0.6721\n",
            "0.6723\n",
            "0.6663\n",
            "0.6341\n",
            "0.675\n",
            "0.6851\n",
            "0.6996\n",
            "0.698\n",
            "0.6956\n",
            "0.69\n",
            "0.6909\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 16, 16]           1,792\n",
            "              ReLU-2           [-1, 64, 16, 16]               0\n",
            "         MaxPool2d-3             [-1, 64, 8, 8]               0\n",
            "            Conv2d-4            [-1, 192, 8, 8]         110,784\n",
            "              ReLU-5            [-1, 192, 8, 8]               0\n",
            "         MaxPool2d-6            [-1, 192, 4, 4]               0\n",
            "            Conv2d-7            [-1, 384, 4, 4]         663,936\n",
            "              ReLU-8            [-1, 384, 4, 4]               0\n",
            "            Conv2d-9            [-1, 256, 4, 4]         884,992\n",
            "             ReLU-10            [-1, 256, 4, 4]               0\n",
            "        MaxPool2d-11            [-1, 256, 2, 2]               0\n",
            "           Linear-12                 [-1, 1000]       1,025,000\n",
            "             ReLU-13                 [-1, 1000]               0\n",
            "           Linear-14                   [-1, 10]          10,010\n",
            "================================================================\n",
            "Total params: 2,696,514\n",
            "Trainable params: 2,696,514\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 0.67\n",
            "Params size (MB): 10.29\n",
            "Estimated Total Size (MB): 10.97\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WhXAk5P_QgHJ",
        "colab_type": "text"
      },
      "source": [
        "## 2. VGG"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXdpPZHoAdU7",
        "colab_type": "code",
        "outputId": "4a039bbf-1c60-43f6-e951-ce00c10f1e5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.datasets as dsets\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchsummary import summary\n",
        "\n",
        "\n",
        "batch_size = 100\n",
        "total_epoch = 50\n",
        "learning_rate = 0.01\n",
        "use_cuda = torch.cuda.is_available()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "print(use_cuda)\n",
        "\n",
        "train_dataset = dsets.CIFAR10(root='./data', train=True, transform=transforms.ToTensor(), download=True)\n",
        "test_dataset = dsets.CIFAR10(root='./data', train=False, transform=transforms.ToTensor())\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "\n",
        "def train(model,train_loader):\n",
        "    model.train()\n",
        "    \n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "    losses = []\n",
        "    for i, (image, label) in enumerate(train_loader):\n",
        "        \n",
        "        if use_cuda:\n",
        "            image = image.cuda()\n",
        "            label = label.cuda()\n",
        "        \n",
        "        pred_label = model(image)\n",
        "        loss = criterion(pred_label, label)\n",
        "        losses.append(loss.item())\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    avg_loss = sum(losses)/len(losses)\n",
        "    return avg_loss\n",
        "\n",
        "\n",
        "def eval(model, test_loader):\n",
        "    model.eval()\n",
        "    device = next(model.parameters()).device.index\n",
        "    \n",
        "    total_cnt = 0\n",
        "    correct_cnt = 0\n",
        "    \n",
        "    for i, (image, label) in enumerate(test_loader):\n",
        "        if use_cuda:\n",
        "            image = image.cuda()\n",
        "            label = label.cuda()\n",
        "\n",
        "        out = model(image)\n",
        "        _, pred_label = torch.max(out.data, 1)\n",
        "        total_cnt += image.data.size()[0]\n",
        "        correct_cnt += (pred_label == label.data).sum().item()\n",
        "        \n",
        "    return correct_cnt / total_cnt"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "True\n",
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|█████████▉| 170467328/170498071 [05:01<00:00, 404156.12it/s]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KbC0bf8RQhYa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SimpleVGG(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleVGG, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=(3,3), padding=(1,1))\n",
        "        self.act1 = nn.ReLU()\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        \n",
        "        \n",
        "        self.conv2 = nn.Conv2d(64, 128, kernel_size=(3,3), padding=(1,1))\n",
        "        self.act2 = nn.ReLU()\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        \n",
        "        self.conv3_1 = nn.Conv2d(128, 256, kernel_size=(3,3), padding=(1,1))\n",
        "        self.act3_1 = nn.ReLU()\n",
        "        self.conv3_2 = nn.Conv2d(256, 256, kernel_size=(3,3), padding=(1,1))\n",
        "        self.act3_2 = nn.ReLU()\n",
        "        self.conv3_3 = nn.Conv2d(256, 256, kernel_size=(3,3), padding=(1,1))\n",
        "        self.act3_3 = nn.ReLU()\n",
        "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        \n",
        "        self.conv4_1 = nn.Conv2d(256, 512, kernel_size=(3,3), padding=(1,1))\n",
        "        self.act4_1 = nn.ReLU()\n",
        "        self.conv4_2 = nn.Conv2d(512, 512, kernel_size=(3,3), padding=(1,1))\n",
        "        self.act4_2 = nn.ReLU()\n",
        "        self.conv4_3 = nn.Conv2d(512, 512, kernel_size=(3,3), padding=(1,1))\n",
        "        self.act4_3 = nn.ReLU()\n",
        "        self.pool4 = nn.AvgPool2d(kernel_size=2, stride=2)\n",
        "        \n",
        "        # Output layer\n",
        "        self.fc1 = nn.Linear(512 * 2 * 2, 512)\n",
        "        self.act5 = nn.ReLU()\n",
        "        self.out = nn.Linear(512, 10)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x1 = x\n",
        "        x2 = self.act1(self.conv1(x1))\n",
        "        x3 = self.pool1(x2)\n",
        "        \n",
        "        x4 = self.act2(self.conv2(x3))\n",
        "        x5 = self.pool2(x4)\n",
        "        \n",
        "        x6 = self.act3_1(self.conv3_1(x5))\n",
        "        x7 = self.act3_2(self.conv3_2(x6))\n",
        "        x8 = self.act3_3(self.conv3_2(x7))\n",
        "        x9 = self.pool3(x8)\n",
        "        \n",
        "        x10 = self.act4_1(self.conv4_1(x9))\n",
        "        x11 = self.act4_2(self.conv4_2(x10))\n",
        "        x12 = self.act4_3(self.conv4_2(x11))\n",
        "        x13 = self.pool4(x12)\n",
        "        \n",
        "        x14 = x13.view(-1, 512 * 2 * 2)\n",
        "        \n",
        "        x15 = self.act5(self.fc1(x14))\n",
        "        \n",
        "        out = self.out(x15)        \n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lcxQ5h2eQyG_",
        "colab_type": "code",
        "outputId": "30c80c09-ba0a-48ff-dd9c-950cca514ff9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        }
      },
      "source": [
        "vgg_model = SimpleVGG().cuda()\n",
        "train_loss_lst = []\n",
        "test_accuracy_lst = []\n",
        "for epoch in range(total_epoch):\n",
        "    train_loss = train(vgg_model, train_loader)\n",
        "    train_loss_lst.append(train_loss)\n",
        "    test_accuracy = eval(vgg_model, test_loader)\n",
        "    test_accuracy_lst.append(test_accuracy)\n",
        "    \n",
        "    print(test_accuracy)\n",
        "\n",
        "summary(vgg_model, input_size = (3,32,32))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-02d4c74f56b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtest_accuracy_lst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvgg_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mtrain_loss_lst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mtest_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvgg_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-352000185b79>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_loader)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0muse_cuda\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/datasets/cifar.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mConverted\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \"\"\"\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m255\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mByteTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mByteStorage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m     \u001b[0;31m# PIL image mode: L, LA, P, I, F, RGB, YCbCr, RGBA, CMYK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'YCbCr'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mtobytes\u001b[0;34m(self, encoder_name, *args)\u001b[0m\n\u001b[1;32m    719\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m         \u001b[0;31m# unpack data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 721\u001b[0;31m         \u001b[0me\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_getencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    722\u001b[0m         \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetimage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36m_getencoder\u001b[0;34m(mode, encoder_name, args, extra)\u001b[0m\n\u001b[1;32m    453\u001b[0m         \u001b[0mencoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"_encoder\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m         \u001b[0;31m# print(encoder, mode, args + extra)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 455\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mextra\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    456\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"encoder %s not available\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mencoder_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pAHIX381dTCg",
        "colab_type": "text"
      },
      "source": [
        "## 3. ResNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCVBYF7eDy_z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SimpleResNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleResNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=(3,3), padding=(1,1))\n",
        "        self.act1 = nn.ReLU()\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        \n",
        "        \n",
        "        self.conv2 = nn.Conv2d(64, 128, kernel_size=(3,3), padding=(1,1))\n",
        "        self.act2 = nn.ReLU()\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        \n",
        "        self.conv3_1 = nn.Conv2d(128, 256, kernel_size=(3,3), padding=(1,1))\n",
        "        self.act3_1 = nn.ReLU()\n",
        "        self.conv3_2 = nn.Conv2d(256, 256, kernel_size=(3,3), padding=(1,1))\n",
        "        self.act3_2 = nn.ReLU()\n",
        "        self.conv3_3 = nn.Conv2d(256, 256, kernel_size=(3,3), padding=(1,1))\n",
        "        self.act3_3 = nn.ReLU()\n",
        "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        \n",
        "        self.conv4_1 = nn.Conv2d(256, 512, kernel_size=(3,3), padding=(1,1))\n",
        "        self.act4_1 = nn.ReLU()\n",
        "        self.conv4_2 = nn.Conv2d(512, 512, kernel_size=(3,3), padding=(1,1))\n",
        "        self.act4_2 = nn.ReLU()\n",
        "        self.conv4_3 = nn.Conv2d(512, 512, kernel_size=(3,3), padding=(1,1))\n",
        "        self.act4_3 = nn.ReLU()\n",
        "        self.pool4 = nn.AvgPool2d(kernel_size=2, stride=2)\n",
        "        \n",
        "        # Output layer\n",
        "        self.fc1 = nn.Linear(512 * 2 * 2, 512)\n",
        "        self.act5 = nn.ReLU()\n",
        "        self.out = nn.Linear(512, 10)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x1 = x\n",
        "        x2 = self.act1(self.conv1(x1))\n",
        "        x3 = self.pool1(x2)\n",
        "        \n",
        "        x4 = self.act2(self.conv2(x3))\n",
        "        x5 = self.pool2(x4)\n",
        "        \n",
        "        x6 = self.act3_1(self.conv3_1(x5))\n",
        "        x7 = self.act3_2(self.conv3_2(x6))\n",
        "        x8 = self.act3_3(self.conv3_2(x7) + x6)\n",
        "        x9 = self.pool3(x8)\n",
        "        \n",
        "        x10 = self.act4_1(self.conv4_1(x9))\n",
        "        x11 = self.act4_2(self.conv4_2(x10))\n",
        "        x12 = self.act4_3(self.conv4_2(x11) + x10)\n",
        "        x13 = self.pool4(x12)\n",
        "        \n",
        "        x14 = x13.view(-1, 512 * 2 * 2)\n",
        "        \n",
        "        x15 = self.act5(self.fc1(x14))\n",
        "        \n",
        "        out = self.out(x15)        \n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rfAjbei8dUq-",
        "colab_type": "code",
        "outputId": "ab5b410b-62f9-43da-8702-684bd68252ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        }
      },
      "source": [
        "resnet_model = SimpleResNet().cuda()\n",
        "train_loss_lst = []\n",
        "test_accuracy_lst = []\n",
        "for epoch in range(total_epoch):\n",
        "    train_loss = train(resnet_model, train_loader)\n",
        "    train_loss_lst.append(train_loss)\n",
        "    test_accuracy = eval(resnet_model, test_loader)\n",
        "    test_accuracy_lst.append(test_accuracy)\n",
        "    \n",
        "    print(test_accuracy)\n",
        "\n",
        "summary(resnet_model, input_size = (3,32,32))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.1446\n",
            "0.1608\n",
            "0.1415\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-193af24a18dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtest_accuracy_lst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresnet_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mtrain_loss_lst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mtest_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresnet_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-352000185b79>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_loader)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0muse_cuda\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m             \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m             \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VOZu47kQSP1E",
        "colab_type": "code",
        "outputId": "db607cd4-d9b5-419a-af48-d8bfd045bce9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 689
        }
      },
      "source": [
        "summary(resnet_model, input_size = (3,32,32))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           1,792\n",
            "              ReLU-2           [-1, 64, 32, 32]               0\n",
            "         MaxPool2d-3           [-1, 64, 16, 16]               0\n",
            "            Conv2d-4          [-1, 128, 16, 16]          73,856\n",
            "              ReLU-5          [-1, 128, 16, 16]               0\n",
            "         MaxPool2d-6            [-1, 128, 8, 8]               0\n",
            "            Conv2d-7            [-1, 256, 8, 8]         295,168\n",
            "              ReLU-8            [-1, 256, 8, 8]               0\n",
            "            Conv2d-9            [-1, 256, 8, 8]         590,080\n",
            "             ReLU-10            [-1, 256, 8, 8]               0\n",
            "           Conv2d-11            [-1, 256, 8, 8]         590,080\n",
            "             ReLU-12            [-1, 256, 8, 8]               0\n",
            "        MaxPool2d-13            [-1, 256, 4, 4]               0\n",
            "           Conv2d-14            [-1, 512, 4, 4]       1,180,160\n",
            "             ReLU-15            [-1, 512, 4, 4]               0\n",
            "           Conv2d-16            [-1, 512, 4, 4]       2,359,808\n",
            "             ReLU-17            [-1, 512, 4, 4]               0\n",
            "           Conv2d-18            [-1, 512, 4, 4]       2,359,808\n",
            "             ReLU-19            [-1, 512, 4, 4]               0\n",
            "        AvgPool2d-20            [-1, 512, 2, 2]               0\n",
            "           Linear-21                  [-1, 512]       1,049,088\n",
            "             ReLU-22                  [-1, 512]               0\n",
            "           Linear-23                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 8,504,970\n",
            "Trainable params: 8,504,970\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 2.87\n",
            "Params size (MB): 32.44\n",
            "Estimated Total Size (MB): 35.32\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kIRHxAXdQ9RZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}